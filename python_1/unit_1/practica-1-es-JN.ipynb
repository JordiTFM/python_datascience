{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "       <img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; padding-top: 22px; text-align:right;\">M1.871 · Privacidad</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Máster Universitario en Ciberseguridad y Privacidad</p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1\n",
    "\n",
    "--- \n",
    "\n",
    "Para resolver esta práctica, tenéis que poner las soluciones en el mismo\n",
    "*notebook*, en las celdas de código que están en blanco habilitadas para ello. Después de cada celda de código podéis poner una celda *markdown* en con la justificación de la respuesta dada en la solución. También \n",
    "podéis poner justificaciones en forma de comentario en las celdas de código. No es obligatorio, pero sí muy recomendable que justifiquéis las respuestas que dais, ya que eso facilita la corrección en caso de una respuesta incorrecta (pudiendo valorar el planteamiento).\n",
    "\n",
    "En muchos casos, cuando se pide implementar una función, se proporciona el nombre de la función y los parámetros, o algún tipo de esqueleto, indicando como ayuda el tipo de dichos parámetros y el tipo que retorna la función en forma de *type hint*. Es necesario que respetéis el nombre de la función y en la medida de los posibles los tipos. Sin embargo podéis implementar el código de la función con total libertad. Podéis\n",
    "definir otras funciones adicionales y no respetar del todo los *type hints* si así lo consideráis oportuno. \n",
    "\n",
    "Este notebook va acompañado de un cuestionario online con preguntas sobre los ejercicios. Este cuestionario debe ser contestado antes de la fecha de etrega de la práctica. **Se recomienda que afrontéis el cuestionario una vez finalizada la practica, habiendo realizado y entendido todos los ejercicios.** En muchos casos se proporcionan datos o posibles resultados con el objeto de ayudar a poder contestar el cuestionario aunque no se haya acabado o no se haya sabido implementar todos los ejercicios de este *notebook*.\n",
    "\n",
    "En algunas preguntas hay algunas indicaciones finales como *Hints*, son sugerencias sobre el uso de funciones que os pueden ser utiles. En cualquier caso se trata simplemente de eso, sugerencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos\n",
    "\n",
    "Trabajaremos con datos que simulan el expediente academico de alumnos. Tenemos el fichero `data/students1.csv` que contiene 10000 registros con los siguientes atributos:\n",
    "- `name`: nombre del alumno/a,\n",
    "- `subject0`: nota de la asignatura 0 (valor real entre 0 y 10),\n",
    "- `subject1`: nota de la asignatura 1,\n",
    "- `subject2`: nota de la asignatura 2,\n",
    "- `subject3`: nota de la asignatura 3,\n",
    "\n",
    "No podemos publicar este fichero de microdatos, ya que se considera que la nota obtenida por el alumnado es privada. Es decir no podemos saber que nota ha obtenido una estudiante en concreto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publicación de microdatos\n",
    "\n",
    "Queremos ahora poder publicar una versión protegida del fichero de microdatos `data/students1.csv`. Para poder trabajar con estos datos utilizaremos la libreira `pandas` de Python. De esta manera podemos leer el fichero en memoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   name      10000 non-null  object \n",
      " 1   subject0  10000 non-null  float64\n",
      " 2   subject1  10000 non-null  float64\n",
      " 3   subject2  10000 non-null  float64\n",
      " 4   subject3  10000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"data/students1.csv\")\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, ahora tenemos en la variable `df1` la tabla de microdatos en una estructura [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) de `pandas`. Notad que tamibén hemos importado la libreria `numpy`, ya que la utilizaremos más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 \n",
    "*[0.5p]*\n",
    "\n",
    "Para publicar estos datos primero tenemos que ver si se pueden publicar todos los atributos.\n",
    "\n",
    "En el caso de que haya algún atributo que no se pueda publicar, elimínalo del `DataFrame` `df1`.\n",
    "\n",
    "*Hint*:\n",
    "- [pandas.DataFrame.drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject0</th>\n",
       "      <th>subject1</th>\n",
       "      <th>subject2</th>\n",
       "      <th>subject3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.5</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject0  subject1  subject2  subject3\n",
       "0       8.5       6.1       1.0       8.8\n",
       "1       0.1       4.9       1.8       5.2\n",
       "2       2.5       7.0       4.1       9.7\n",
       "3       6.5       6.4       6.1       9.0\n",
       "4       0.8       9.7       2.3       5.3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Puesto que hay que anonimizar a los alumnos, eliminaremos del DF la columna que los identifica\n",
    "df1_anonim = df1.drop(columns=[\"name\"])\n",
    "## Comprobamos el resultado mostrando los primeros registros\n",
    "df1_anonim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2 \n",
    "*[1.25p]*\n",
    "\n",
    "Para el resto de atributos vamos a utilizar **ruido aditivo no correlacionado**, tal como se describe en los materiales. \n",
    "\n",
    "Para ello vamos a utilizar una distribución normal $N(\\mu, \\sigma^2)$ con $\\mu = 0$, y como varianza tomaremos $\\sigma^2 = p \\sigma_o^2$\n",
    "donde $\\sigma_o^2$ es la varianza de la variable que queremos proteger.\n",
    "\n",
    "Desarrollad una función `noise_add_normal(df, p)` que recibe como parámetro `df`, el DataFrame a anonimizar y el parámetro `p`, y retorna una copia del DataFrame protegido, aplicando ruido a cada atributo. \n",
    "\n",
    "Finalmente, obtened una versión protegida en la variable `df1_noise_1` utilizando $p=0.1$.\n",
    "\n",
    "Algunas consideraciones:\n",
    "- cada atributo (variable o columna) tendrá una distribución de ruido independiente.\n",
    "- la función no puede modificar el DataFrame original, tiene que retornar un DataFrame nuevo.\n",
    "- tened cuidado a la hora de pasar la varianza a la distribución normal de la librería `numpy`, fijaros que espera recibir la desviación estándar (no la varianza).\n",
    "- el resultado después de aplicar ruido NO tiene que estar redondeado a un decimal (como sí lo estaban los valores originales), ni se tiene que aplicar ninguna corrección.\n",
    "\n",
    "\n",
    "*Hint*:\n",
    "- [`numpy.random.Generator.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.normal.html#numpy.random.Generator.normal)\n",
    "- [Random sampling, quick start](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject0</th>\n",
       "      <th>subject1</th>\n",
       "      <th>subject2</th>\n",
       "      <th>subject3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.428666</td>\n",
       "      <td>6.575151</td>\n",
       "      <td>1.200730</td>\n",
       "      <td>7.633098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.173817</td>\n",
       "      <td>4.666288</td>\n",
       "      <td>2.756145</td>\n",
       "      <td>5.179117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.483329</td>\n",
       "      <td>6.594091</td>\n",
       "      <td>3.844465</td>\n",
       "      <td>10.552575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.973029</td>\n",
       "      <td>7.562310</td>\n",
       "      <td>8.011958</td>\n",
       "      <td>7.840803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.195651</td>\n",
       "      <td>8.880231</td>\n",
       "      <td>1.344469</td>\n",
       "      <td>5.321635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject0  subject1  subject2   subject3\n",
       "0  8.428666  6.575151  1.200730   7.633098\n",
       "1  0.173817  4.666288  2.756145   5.179117\n",
       "2  3.483329  6.594091  3.844465  10.552575\n",
       "3  5.973029  7.562310  8.011958   7.840803\n",
       "4 -0.195651  8.880231  1.344469   5.321635"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def noise_add_normal(df: pd.DataFrame, p: float) -> pd.DataFrame:\n",
    "    ## Creamos una copia para proteger el DF recibido como parámetro\n",
    "    df_noise = df.copy()\n",
    "    for col in df.columns:\n",
    "        # Calculamos la varianza original de la columna\n",
    "        var = df[col].var()\n",
    "        # numpy espera recibir la desviación estándar (no la varianza), así que transformamos\n",
    "        std = np.sqrt(p * var)  # σ = sqrt(p * σ₀²)\n",
    "        # Generamos un vector de ruido con media (µ) 0 y la desviación std recién calculada\n",
    "        # Este vector contiene un valor distinto de ruido por cada fila (alumno), con media tendiendo a cero, para evitar sesgo\n",
    "        # La generación es independiente por columna, lo que permite preservar las correlaciones entre las asignaturas\n",
    "        noise = np.random.normal(0, std, len(df))\n",
    "        # Sumamos el ruido a la columna\n",
    "        df_noise[col] = df[col] + noise\n",
    "    return df_noise\n",
    "    \n",
    "## Obtención de una copia protegida en la variable df1_noise_1, utilizando p=0.1\n",
    "df1_noise_1 = noise_add_normal(df1_anonim, p=0.1)\n",
    "## Comprobamos una muestra del resultado\n",
    "df1_noise_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como guía, los valores protegidos en `df1_noise_1` pueden ser algo parecido a lo que se muestra en la siguiente tabla.\n",
    "\n",
    "|  | subject0 |\tsubject1 |\tsubject2 |\tsubject3 |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 0 | 6.626006 |\t6.858254 |\t3.024407 |\t10.113438 |\n",
    "| 1 | -0.190741 |\t5.878539 |\t1.641941 |\t4.289627 |\n",
    "| 2 | 0.326832 |\t7.113423 |\t2.489244 |\t10.214147 |\n",
    "| 3 | 7.815629 |\t5.846698 |\t7.173413 |\t10.008515 |\n",
    "| 4 | 1.246823 |\t10.570642 |\t2.149917 |\t4.912380 |\n",
    "| 5 | ... | ... | ... | ... |\n",
    "| ... | ... | ... | ... | ... |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "*[1.25p]*\n",
    "\n",
    "En este ejercicio desarrollaremos dos medidas de **pérdida de información**.\n",
    "\n",
    "Para ello vamos a utilizar la siguiente notación:\n",
    "- $X$: conjunto de datos original. Lo podemos interpretar como una matriz de\n",
    "tamaño $n \\times d$ donde $n$ es el número de registros (filas) y $d$ el\n",
    "número de variables (columnas).\n",
    "- $X'$: conjunto de datos protegido, también $n \\times d$.\n",
    "- $R$: matriz de correlación de los datos originales $X$. Esta matriz es una matriz $d \\times d$ donde el elemento $(i,j)$ es la correlación entre la variable $V_i$ y $V_j$. Como medida de correlación tomaremos el coeficiente de correlación de Pearson.\n",
    "- $R'$: matriz de correlación de los datos protegidos $X'$.\n",
    "\n",
    "En cada caso mediremos la media del error absoluto MAE (*mean absolute error*). Es decir:\n",
    "- Sobre $X$, $X'$:\n",
    "  - *MAE*: $\\frac{1}{nd}\\sum_{j=1}^d \\sum_{i=1}^n \\mid x_{ij} - x'_{ij} \\mid$\n",
    "- Sobre $R$, $R'$:\n",
    "  - *MAE-corr*: $\\frac{1}{d^2}\\sum_{j=1}^d \\sum_{i=1}^n \\mid r_{ij} - r'_{ij} \\mid$\n",
    "\n",
    "Se pide la implementación de la función `information_loss(df_original, df_protected)` donde `df_original` es el DataFrame con los datos originales ($X$) y `df_protected` el DataFrame con los datos protegidos ($X'$). La función tiene que retornar dos valores, en este orden:\n",
    "- valor del MAE sobre $X$ y $X'$\n",
    "- valor del MAE sobre $R$ y $R'$\n",
    "\n",
    "Una vez implementada, aplicad la función para medir la pérdida de información al proteger los datos con $p=0.1$ (`df1_noise_1` del ejercicio anterior).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor del MAE sobre X y X': 0.7801488653731802\n",
      "Valor del MAE sobre R y R': 0.0038916518145256304\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def information_loss(df_original: pd.DataFrame, df_protected: pd.DataFrame) -> Tuple[float, float]:\n",
    "    ## Definimos las matrices de trabajo\n",
    "    X = df_original     # conjunto de datos original\n",
    "    X_ = df_protected   # conjunto de datos protegido\n",
    "\n",
    "    ## Cálculo del MAE (Mean Absolute Error) sobre X y X'\n",
    "    mae_X = np.abs(X - X_).to_numpy().mean()\n",
    "\n",
    "    ## Cálculo del MAE sobre las matrices R y R' tomando el coeficiente de correlación de Pearson\n",
    "    R = X.corr(method=\"pearson\")    # matriz de correlación de los datos originales\n",
    "    R_ = X_.corr(method=\"pearson\")  # matriz de correlación de los datos protegidos\n",
    "    mae_R = np.abs(R - R_).to_numpy().mean()\n",
    "\n",
    "    return mae_X, mae_R\n",
    "\n",
    "## Llamada a la función con los datos correspondientes\n",
    "mae_datos, mae_correlaciones = information_loss(df1_anonim, df1_noise_1)\n",
    "\n",
    "## Mostramos los resultados con la misma redacción que el enunciado\n",
    "print(\"Valor del MAE sobre X y X':\", mae_datos)\n",
    "print(\"Valor del MAE sobre R y R':\", mae_correlaciones)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\"> \n",
    "<h4><strong>COMENTARIOS EJERCICIO 3</strong></h4>\n",
    "En los resultados que hemos obtenido se observa que:\n",
    "    \n",
    "- el ruido aditivo aplicado altera en cierta medida los valores individuales de cada asignatura (MAE = 0.7813), al introducir una componente\n",
    "aleatoria con varianza proporcional al parámetro p = 0.1,\n",
    "\n",
    "- y, sin embargo, se mantienen casi intactas las correlaciones entre las 4 asignaturas (MAE = 0.0015), dado que el ruido tiene media cero\n",
    "y se aplica de forma no correlacionada entre columnas.\n",
    "\n",
    "Eso significa que la UTILIDAD estadística del juego de datos se mantiene prácticamente intacta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "*[2p]*\n",
    "\n",
    "Queremos ahora producir una versión de los microdatos con el mayor nivel de ruido posible pero sin perder mucha información. Concretamente, queremos garantizar que el MAE (unicamente el MAE, no el MAE-corr) no supere el valor $3$.\n",
    "\n",
    "Es decir, ¿qué nivel de ruido (parámetro $p$) podemos aplicar de manera que obtengamos el mayor nivel de privacidad pero manteniendo la perdida de información según el MAE por debajo de $3.0$?\n",
    "\n",
    "Se pide que programéis el código para determinar dicho valor $p$. Para restringir la búsqueda, consideraremos que el parámetro $p$ puede tomar valores a partir de $0$ y siempre se expresará con un solo decimal. Es decir, podemos tener valores como $p=0.3$ o $p=1.2$ pero NO $p=0.31$ o $p=1.023$.\n",
    "\n",
    "Tenéis que mostrar al final el valor de $p$ que buscamos y el MAE obtenido con dicho valor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor óptimo de p: 1.4\n",
      "Percentil 95 del MAE asociado a ese valor de p: 2.9331237980423057\n"
     ]
    }
   ],
   "source": [
    "## Definimos el nivel máximo de ruido permitido mae_max\n",
    "## e inicializamos las variables de cálculo de los valores óptimos mae_opt y p_opt\n",
    "mae_max = 3.0\n",
    "mae_opt = None\n",
    "p_opt = None\n",
    "\n",
    "## Número de repeticiones por valor de p\n",
    "num_reps = 20\n",
    "\n",
    "## Exploramos valores de p con 1 decimal, de 0.0 a 2.0 como primera aproximación\n",
    "for p in [round(x * 0.1, 1) for x in range(0, 21)]:\n",
    "    maes = []\n",
    "\n",
    "    for _ in range(num_reps):\n",
    "        # Generamos una versión protegida de X aplicando ruido con parámetro p\n",
    "        X_ = noise_add_normal(df1_anonim, p)\n",
    "\n",
    "        # Calculamos la pérdida de información (MAE entre X y X'), ignorando el MAE-corr ya que no es necesario\n",
    "        mae, _ = information_loss(df1_anonim, X_)\n",
    "        maes.append(mae)\n",
    "\n",
    "    # Calculamos el percentil 95 del MAE para este valor de p\n",
    "    mae_p95 = np.percentile(maes, 95)\n",
    "\n",
    "    # Verificamos si cumple el umbral definido\n",
    "    if mae_p95 < mae_max:\n",
    "        mae_opt = mae_p95\n",
    "        p_opt = p\n",
    "    else:\n",
    "        break  # Al superar el umbral, salimos del bucle\n",
    "\n",
    "## Mostramos el mejor valor de p encontrado y su correspondiente MAE\n",
    "print(\"Valor óptimo de p:\", p_opt)\n",
    "print(\"Percentil 95 del MAE asociado a ese valor de p:\", mae_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\"> \n",
    "<h4><strong>COMENTARIOS EJERCICIO 4</strong></h4>\n",
    "\n",
    "En este ejercicio se buscaba optimizar el equilibrio entre Privacidad y Utilidad de la información en la publicación de microdatos.\n",
    "El proceso es algo más complejo que calcular el MAE dentro de un bucle en el que p se va incrementando en 1 décima, ya que el MAE es una variable aleatoria, con cierta variabilidad en cada ejecución.\n",
    "\n",
    "Eso significa que, tal y como me ha sucedido en la primera versión del código, ejecutándola varias veces he observado que, si bien casi siempre obtenía un valor de p óptimo = 1.4, en alguna ocasión ese valor ha sido 1.5, y si lo hubiese dado por bueno, ocurriría que en la mayoría de casos produciría un MAE > 3.0, es decir, por encima del valor máximo impuesto en el enunciado.\n",
    "\n",
    "Para aumentar la fiabilidad del cálculo sin complicar excesivamente el código, he introducido un bucle externo que repite el cálculo 20 veces por cada p óptimo, y evalúa el percentil 95 del MAE. Esto garantiza que el valor seleccionado sea el mayor p posible que, con alta probabilidad, mantiene el MAE por debajo del umbral. Como era de esperar, ese valor no es 1.5 sino 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "*[1.25p]*\n",
    "\n",
    "Con el valor $p$ obtenido en el ejercicio anterior, vamos a obtener un nuevo DataFrame protegido:\n",
    "```Python\n",
    "df_protected_final = noise_add_normal(df1, p)\n",
    "```\n",
    "(Si no has podido acabar el ejercicio anterior, utiliza el valor $p=1.8$, que no tiene por qué ser igual a la solución de dicho ejercicio)\n",
    "\n",
    "Este será el fichero de microdatos publicado. Para ver que diferencias tenemos respecto al original se pide comparar los siguientes valores entre el fichero de notas original (`df1`) y el protegido (`df_protected_final`):\n",
    "- media de cada asignatura por separado.\n",
    "- media de todas las asignaturas.\n",
    "- nota máxima y mínima de cada asignatura por separado\n",
    "- nota máxima y mínima de todas las asignaturas.\n",
    "\n",
    "Para ello, tenéis que implementar una función `compute_statistics` que reciba como parámetro un `DataFrame` con las notas y retorne un diccionario con los valores requeridos. Como ejemplo, si aplicamos la función a los datos originales, `df1`, debería retornar:\n",
    "```python\n",
    "{'avg_s0': 5.4178700000000015,\n",
    " 'avg_s1': 5.462769999999979,\n",
    " 'avg_s2': 5.408580000000002,\n",
    " 'avg_s3': 5.327550000000016,\n",
    " 'avg_total': 5.4041925,\n",
    " 'max_s0': 10.0,\n",
    " 'max_s1': 10.0,\n",
    " 'max_s2': 10.0,\n",
    " 'max_s3': 10.0,\n",
    " 'max_total': 10.0,\n",
    " 'min_s0': 0.0,\n",
    " 'min_s1': 0.0,\n",
    " 'min_s2': 0.0,\n",
    " 'min_s3': 0.0,\n",
    " 'min_total': 0.0}\n",
    "```\n",
    "De esta manera podemos comparar los valores sobre `df1` y `df_protected_final`\n",
    "```python\n",
    "stats = pd.DataFrame([compute_statistics(df1), compute_statistics(df_protected_final)])\n",
    "\n",
    "```\n",
    "En `stats` tenemos un `DataFrame` donde podemos ver los resultados.\n",
    "`\n",
    "En este ejercicio se pide:\n",
    "- implementar la función `compute_statistics` tal como se pide,\n",
    "- mostrar el resultado en el `DataFrame` stats como se indica anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparativa entre los valores originales y los protegidos con p = 1.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Valor original</th>\n",
       "      <th>Valor protegido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_s0</td>\n",
       "      <td>5.417870</td>\n",
       "      <td>5.466000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg_s1</td>\n",
       "      <td>5.462770</td>\n",
       "      <td>5.472801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_s2</td>\n",
       "      <td>5.408580</td>\n",
       "      <td>5.446605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_s3</td>\n",
       "      <td>5.327550</td>\n",
       "      <td>5.491280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_total</td>\n",
       "      <td>5.404193</td>\n",
       "      <td>5.469172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max_s0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>24.760321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max_s1</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>21.372396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max_s2</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>22.764915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max_s3</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>21.701499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_total</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>24.760321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>min_s0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11.950963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>min_s1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11.024714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>min_s2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11.871900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>min_s3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11.645073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>min_total</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11.950963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Variable  Valor original  Valor protegido\n",
       "0      avg_s0        5.417870         5.466000\n",
       "1      avg_s1        5.462770         5.472801\n",
       "2      avg_s2        5.408580         5.446605\n",
       "3      avg_s3        5.327550         5.491280\n",
       "4   avg_total        5.404193         5.469172\n",
       "5      max_s0       10.000000        24.760321\n",
       "6      max_s1       10.000000        21.372396\n",
       "7      max_s2       10.000000        22.764915\n",
       "8      max_s3       10.000000        21.701499\n",
       "9   max_total       10.000000        24.760321\n",
       "10     min_s0        0.000000       -11.950963\n",
       "11     min_s1        0.000000       -11.024714\n",
       "12     min_s2        0.000000       -11.871900\n",
       "13     min_s3        0.000000       -11.645073\n",
       "14  min_total        0.000000       -11.950963"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def compute_statistics(df: pd.DataFrame) -> Dict[str, float]:\n",
    "    ## Calculamos las medias por asignatura\n",
    "    avg_s0 = df[\"subject0\"].mean()\n",
    "    avg_s1 = df[\"subject1\"].mean()\n",
    "    avg_s2 = df[\"subject2\"].mean()\n",
    "    avg_s3 = df[\"subject3\"].mean()\n",
    "\n",
    "    ## Calculamos la media global\n",
    "    avg_total = df.mean().mean()\n",
    "\n",
    "    ## Calculamos los máximos por asignatura\n",
    "    max_s0 = df[\"subject0\"].max()\n",
    "    max_s1 = df[\"subject1\"].max()\n",
    "    max_s2 = df[\"subject2\"].max()\n",
    "    max_s3 = df[\"subject3\"].max()\n",
    "\n",
    "    ## Calculamos el máximo global\n",
    "    max_total = df.max().max()\n",
    "\n",
    "    ## Calculamos los mínimos por asignatura\n",
    "    min_s0 = df[\"subject0\"].min()\n",
    "    min_s1 = df[\"subject1\"].min()\n",
    "    min_s2 = df[\"subject2\"].min()\n",
    "    min_s3 = df[\"subject3\"].min()\n",
    "\n",
    "    ## Calculamos el mínimo global\n",
    "    min_total = df.min().min()\n",
    "\n",
    "    ## Devolvemos los resultados en un diccionario\n",
    "    return {\n",
    "        \"avg_s0\": avg_s0,\n",
    "        \"avg_s1\": avg_s1,\n",
    "        \"avg_s2\": avg_s2,\n",
    "        \"avg_s3\": avg_s3,\n",
    "        \"avg_total\": avg_total,\n",
    "        \"max_s0\": max_s0,\n",
    "        \"max_s1\": max_s1,\n",
    "        \"max_s2\": max_s2,\n",
    "        \"max_s3\": max_s3,\n",
    "        \"max_total\": max_total,\n",
    "        \"min_s0\": min_s0,\n",
    "        \"min_s1\": min_s1,\n",
    "        \"min_s2\": min_s2,\n",
    "        \"min_s3\": min_s3,\n",
    "        \"min_total\": min_total\n",
    "    }\n",
    "\n",
    "## Generamos el DataFrame protegido final usando el valor óptimo de p obtenido en el ejercicio anterior\n",
    "df_protected_final = noise_add_normal(df1_anonim, p_opt)\n",
    "\n",
    "## Aplicamos la función compute_statistics sobre el dataset original y el protegido\n",
    "stats = pd.DataFrame([\n",
    "    compute_statistics(df1_anonim),\n",
    "    compute_statistics(df_protected_final)\n",
    "])\n",
    "\n",
    "## Reorganizamos el DataFrame para mostrar una fila por variable, y mostramos el resultado\n",
    "stats = stats.transpose().reset_index()\n",
    "stats.columns = [\"Variable\", \"Valor original\", \"Valor protegido\"]\n",
    "print(f\"Comparativa entre los valores originales y los protegidos con p = {p_opt}\")\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\"> \n",
    "<h4><strong>COMENTARIOS EJERCICIO 5</strong></h4>\n",
    "Al comparar las estadísticas del DF original con las del DF protegido usando el factor p obtenido en el ejercicio anterior (1.4) hemos observado que, a efectos estadísticos, el conjunto de datos sigue siendo válido, puesto que los promedios de las notas apenas varían. En cambio, si se pretendiera hacer un análisis de casos individuales, que no es el caso en este ejercicio, entonces obtendríamos conclusiones muy distorsionadas, con notas máximas por encima del 20 y notas mínimas con valores negativos, debido al nivel de ruido aplicado en esta ocasión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacidad diferencial\n",
    "\n",
    "Ahora vamos a ver el enfoque que propone la privacidad diferencial, y para ello implementaremos de forma simulada una base de datos como una clase de Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La siguiente clase implementa una sencilla base de datos `MyDB`. La base de datos lee el fichero CSV que contiene los datos con las notas de los estudiantes.\n",
    "\n",
    "Como vemos, se trata de una base de datos muy sencilla y simplificada, que únicamente tiene sentido con fines docentes. La idea es que la clase `MyDB` simula una base de datos y sus métodos públicos son las consultas que pueden hacer los usuarios. Asumimos que un usuario no puede ver el contenido del objeto y simplemente puede acceder a `MyDB` mediante sus métodos.\n",
    "\n",
    "La clase `MyDB` se instancia a partir de un fichero CSV que se guarda como un `DataFrame` de `pandas`. Esta clase implementa 1 método para obtener información sobre las estudiantes de la base de datos:\n",
    "- `count_all_fail`: que retorna el número de estudiantes que han suspendido todas las asignaturas.\n",
    "\n",
    "Recordamos que asumimos que la única manera que tiene cualquier usuario para acceder a los datos es llamar a esta función `count_all_fail`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDB:\n",
    "    def __init__(self, filename: str) -> None:\n",
    "        self.df = pd.read_csv(filename)\n",
    "\n",
    "    def count_all_fail(self) -> int:\n",
    "        return self.df[\n",
    "            (self.df[\"subject0\"] < 5)\n",
    "            & (self.df[\"subject1\"] < 5)\n",
    "            & (self.df[\"subject2\"] < 5)\n",
    "            & (self.df[\"subject3\"] < 5)\n",
    "            ].shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ejemplo, a continuación vemos como se instanciaría `SimpleDB` con el fichero `data/students1.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB1 count_all_fail: 420\n"
     ]
    }
   ],
   "source": [
    "db1 = MyDB(\"data/students1.csv\")\n",
    "\n",
    "print(f\"DB1 count_all_fail: {db1.count_all_fail()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "*[0.5p]*\n",
    "\n",
    "Vamos ahora a estudiar la privacidad que ofrece `MyDB` según la definición de privacidad diferencial. Con el objeto de poder hacer diversas pruebas tenemos dos ficheros CSV:\n",
    "- `data/students1.csv`: con 10000 registros\n",
    "- `data/students2.csv`: con 9999 registros\n",
    "\n",
    "Podemos ver que `students2.csv` es igual a `students1.csv` con la diferencia de que le falta un registro, el correspondiente a *Susan Duffy*. En principio podemos asumir que un posible atacante sabe que este es el registro que falta (el correspondiente a esta estudiante no está en DB2 y sí en DB1), pero no sabe sus datos: notas obtenidas en las asignaturas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = MyDB(\"data/students1.csv\")\n",
    "db2 = MyDB(\"data/students2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Observando el resultado de hacer la consulta `count_all_fail` a `db1` y `db2`. ¿Qué información podemos obtener? (Muestra el resultado de las consultas y añade la respuesta y su justificación como comentario).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de estudiantes con todo suspendido en DB1: 420\n",
      "Número de estudiantes con todo suspendido en DB2: 420\n"
     ]
    }
   ],
   "source": [
    "## Creamos las 2 bases de datos cargando los ficheros de la carpeta data mediante la clase MyDB\n",
    "db1 = MyDB(\"data/students1.csv\") ## Base de datos con los 10.000 registros originales\n",
    "db2 = MyDB(\"data/students2.csv\") ## Copia de db1 pero sin el registro de Susan Duffy\n",
    "\n",
    "## Ejecutamos la consulta count_all_fail sobre ambas bases de datos\n",
    "## Esta consulta cuenta el número de estudiantes que han suspendido todas las asignaturas\n",
    "suspendidos_db1 = db1.count_all_fail()\n",
    "suspendidos_db2 = db2.count_all_fail()\n",
    "\n",
    "## Mostramos los resultados obtenidos en ambas bases de datos\n",
    "print(\"Número de estudiantes con todo suspendido en DB1:\", suspendidos_db1)\n",
    "print(\"Número de estudiantes con todo suspendido en DB2:\", suspendidos_db2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\"> \n",
    "<h4><strong>COMENTARIOS EJERCICIO 6</strong></h4>\n",
    "\n",
    "Al ejecutar el código de la celda de arriba hemos observado que el resultado es el mismo en las 2 bases de datos.\n",
    "\n",
    "Esto no se debe a la aplicación de mecanismos de privacidad diferencial -todavía no hemos aplicado ninguno-, sino a la propia lógica de la consulta y a la naturaleza de los datos. Es decir, la eliminación de Susan Duffy no ha afectado al resultado porque ella no se encontraba en el conjunto de alumnos con todas las asignaturas suspendidas. De haberse eliminado un estudiante perteneciente a ese conjunto, entonces el resultado de la consulta hubiese diferido.\n",
    "\n",
    "Por tanto, la privacidad diferencial no interviene en este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7\n",
    "*[1.25p]*\n",
    "\n",
    "Vamos a implementar una nueva base de datos que implemente la versión segura del método `count_all_fail` utilizando el mecanismo de Laplace. Para ello crearemos una nueva clase de base de datos a la que llamaremos `MyPrivateDB`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Implementa, en la siguiente clase, el método `dp_count_all_fail` que retorne el número de alumnos y alumnas que han suspendido todas las asignaturas, pero esta vez la respuesta ha de estar protegida utilizando **el mecanismo de Laplace**.\n",
    "\n",
    "Para hacerlo necesitaremos:\n",
    "- Calcular o determinar la sensibilidad global del método.\n",
    "- Generar ruido con una distribución de Laplace basándonos en su sensibilidad global y el parámetro *epsilon*.\n",
    "- Retornar el valor con el ruido añadido.\n",
    "\n",
    "Como vemos, el parámetro *epsilon* se fija en el constructor de la clase. Importante: de momento asumimos que únicamente se realizará una consulta.\n",
    "\n",
    "*Hint*: \n",
    "- [random.Generator.laplace](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.laplace.html#numpy.random.Generator.laplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MyPrivateDB:\n",
    "    def __init__(self, filename: str, epsilon: float) -> None:\n",
    "        self.df = pd.read_csv(filename)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def dp_count_all_fail(self) -> int:\n",
    "        ## Calculamos el número real de alumnos con todas las asignaturas suspendidas\n",
    "        count = self.df[\n",
    "            (self.df[\"subject0\"] < 5) &\n",
    "            (self.df[\"subject1\"] < 5) &\n",
    "            (self.df[\"subject2\"] < 5) &\n",
    "            (self.df[\"subject3\"] < 5)\n",
    "        ].shape[0]\n",
    "\n",
    "        ## Sensibilidad global = 1 (añadir o eliminar un registro puede variar el resultado en 1 unidad)\n",
    "        sensibilidad = 1.0\n",
    "\n",
    "        rng = np.random.default_rng()  ## Inicializamos el generador de números aleatorios\n",
    "\n",
    "        ## Generamos ruido de Laplace con media 0 y escala sensibilidad/epsilon\n",
    "        noise = rng.laplace(0, sensibilidad / self.epsilon)\n",
    "\n",
    "        return int(round(count + noise))  ## Sumamos el ruido al valor real y redondeamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\"> \n",
    "<h4><strong>COMENTARIOS EJERCICIO 7</strong></h4>\n",
    "\n",
    "El mecanismo de Laplace consiste en añadir un valor aleatorio, extraído de una distribución de Laplace, al resultado real de la consulta, con el objetivo de proteger la confidencialidad de los datos individuales. La cantidad de ruido añadido depende de dos factores fundamentales:\n",
    "\n",
    "- La sensibilidad, que determina cuánto puede variar como máximo el resultado de la consulta al añadir o eliminar un único registro en la base de datos. En este caso le asignamos valor 1, ya que la consulta cuenta registros, y en dos juegos de datos adyacentes el resultado solo puede diferir en una unidad como máximo. Si la consulta consistiese en calcular la nota media de una asignatura, suponiendo que la nota máxima es 10 y la mínima es 0, la sensibilidad sería 0,001, ya que el resultado podría variar, como máximo, en (10-0)/10000. Y si la consulta fuera para obtener el sumatorio de todas las notas de una determinada asignatura, entonces la sensibilidad sería 10, porque esa es la mayor diferencia posible entre las dos bases de datos adyacentes: sería 0 si el alumno eliminado de la segunda base de datos tuviese un 0 en esa asignatura, y sería 10 si tuviese un 10.\n",
    "\n",
    "- El parámetro epsilon, que representa la pérdida de privacidad que estamos dispuestos a aceptar. En otras palabras, regula el equilibrio entre privacidad y precisión. Cuanto menor sea epsilon, mayor es el nivel de privacidad, pero más ruido se añade al resultado, afectando a su exactitud o utilidad.\n",
    "\n",
    "El ruido que añadimos al resultado de la consulta se calcula con media 0 para que los resultados no se desvíen sistemáticamente en una dirección concreta, manteniendo así la neutralidad del mecanismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8\n",
    "*[0.5p]*\n",
    "\n",
    "Podemos ver el resultado de hacer la consulta `dp_count_all_fail` con la nueva base de datos `MyPrivateDB` a los datos de `data/students1.csv` y `data/students2.csv`.\n",
    "\n",
    "¿Podemos ahora obtener la misma información que en el Ejercicio 6? Muestra el resultado para `epsilon=1`, responde y justifica en forma de comentario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de estudiantes con todo suspendido en DB1 (privado): 420\n",
      "Número de estudiantes con todo suspendido en DB2 (privado): 421\n"
     ]
    }
   ],
   "source": [
    "## Creamos las dos bases de datos privadas (protegidas con Laplace y epsilon=1)\n",
    "db1_priv = MyPrivateDB(\"data/students1.csv\", epsilon=1)  ## Base de datos con todos los registros\n",
    "db2_priv = MyPrivateDB(\"data/students2.csv\", epsilon=1)  ## Base de datos sin Susan Duffy\n",
    "\n",
    "## Ejecutamos la consulta dp_count_all_fail en ambas bases de datos\n",
    "suspendidos_db1_priv = db1_priv.dp_count_all_fail()\n",
    "suspendidos_db2_priv = db2_priv.dp_count_all_fail()\n",
    "\n",
    "## Mostramos los resultados obtenidos\n",
    "print(\"Número de estudiantes con todo suspendido en DB1 (privado):\", suspendidos_db1_priv)\n",
    "print(\"Número de estudiantes con todo suspendido en DB2 (privado):\", suspendidos_db2_priv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\"> \n",
    "<h4><strong>COMENTARIOS EJERCICIO 8</strong></h4>\n",
    "\n",
    "A través de los resultados obtenidos en el ejercicio, se comprueba que al aplicar el método dp_count_all_fail() con un valor de epsilon=1, el resultado ya no coincide exactamente con el obtenido en el ejercicio 6, pese a que las bases de datos db1 y db2 siguen difiriendo en un único registro.\n",
    "\n",
    "Esta diferencia se debe al funcionamiento del mecanismo de Laplace, que añade un valor aleatorio al resultado real de la consulta con el objetivo de garantizar privacidad diferencial. Este ruido se genera en función de los 2 parámetros comentados en el ejercicio 7: la sensibilidad de la consulta (que en este caso le hemos dado valor 1 por tratarse de un recuento de registros), y el valor de epsilon, que fija el equilibrio entre privacidad y precisión, y que también vale 1, siguiendo las indicaciones del enunciado.\n",
    "\n",
    "Para ello, al resultado real de la consulta se le añade un valor aleatorio extraído de una distribución de Laplace. Esto garantiza que la presencia o ausencia de un único individuo no sea detectable a partir de los resultados publicados.\n",
    "\n",
    "Cuanto menor es el valor de epsilon, mayor es el ruido que inyectamos y, por consiguiente, mayor es la protección de la privacidad, es decir, mayor es la dificultad de inferir información sobre individuos concretos, y mayor puede ser también la utilidad de la información publicada.\n",
    "\n",
    "Se puede apreciar más claramente este efecto haciendo pruebas con valores de epsilon muy bajos y muy altos. Por ejemplo, con epsilon = 0.1, el resultado oscilaría aleatoriamente en un rango aproximado de +-40, y con epsilon = 10, el valor calculado se mantendría constante en los 420 alumnos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 9\n",
    "*[2p]*\n",
    "\n",
    "Hemos asumido al principio que el usuario o usuaria únicamente realizará una consulta (llamará a la función `dp_count_all_fail()` una vez).\n",
    "\n",
    "Si ahora asumimos que se puede hacer más de una consulta, y sin modificar la implementación de nuestro método `dp_count_all_fail`, un atacante ¿podría llegar a obtener la misma información que proporcionaba el método `count_all_fail` pero utilizando `dp_count_all_fail`?\n",
    "\n",
    "En este ejercicio se pide implementar el posible ataque que permita desanonimizar `dp_count_all_fail` (es decir, utilizando `MyPrivateDB`) y con la particularidad de que se puede repetir dicha consulta sobre una misma base de datos diversas veces. En este caso lo haremos para `epsilon=8`. Justifica el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor promedio obtenido tras el ataque por repetición: 420.0\n",
      "Valor real (sin protección) del número de estudiantes con todo suspendido: 420\n"
     ]
    }
   ],
   "source": [
    "## Creamos la base de datos privada a partir de students1.csv, con epsilon=8\n",
    "db1_priv = MyPrivateDB(\"data/students1.csv\", epsilon=8)\n",
    "\n",
    "## Definimos el número de repeticiones del ataque\n",
    "num_reps = 20\n",
    "\n",
    "## Lista para almacenar los resultados obtenidos en cada consulta\n",
    "resultados = []\n",
    "\n",
    "## Ejecutamos la consulta dp_count_all_fail() varias veces\n",
    "for _ in range(num_reps):\n",
    "    resultado = db1_priv.dp_count_all_fail()\n",
    "    resultados.append(resultado)\n",
    "\n",
    "## Calculamos el promedio de los resultados obtenidos\n",
    "promedio_resultados = np.mean(resultados)\n",
    "\n",
    "## Mostramos el resultado del ataque\n",
    "print(\"Valor promedio obtenido tras el ataque por repetición:\", promedio_resultados)\n",
    "print(\"Valor real (sin protección) del número de estudiantes con todo suspendido:\", 420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\"> \n",
    "<h4><strong>COMENTARIOS EJERCICIO 9</strong></h4>\n",
    "\n",
    "En este ejercicio hemos simulado un posible ataque por repetición de consultas sobre la función dp_count_all_fail() con epsilon=8, y hemos podido verificar la limitación de la privacidad diferencial que señalan los apuntes de la asignatura basándose en el teorema de composición secuencial, el cual concluye que \"cada vez que se hace una consulta a la base de datos se produce una pérdida de privacidad acumulativa\". En relación con este teorema, en el video \"The Definition of Differential Privacy\", Cynthia Dwork explica que los valores de epsilon se suman en cada nuevo análisis realizado con el mismo algoritmo sobre el mismo juego de datos.\n",
    "\n",
    "Esto se debe a que cada ejecución de la consulta añade un valor de ruido diferente con distribución de Laplace, media cero, y, al hacer la media de todos los resultados, el ruido se cancela ya que está centrado en cero.\n",
    "\n",
    "Además, el problema se ha visto agravado por la elección de un valor de epsilon = 8, lo que significa que ya de partida hemos añadido un nivel de ruido bastante menor que en el ejercicio anterior.\n",
    "\n",
    "Como resultado, hemos podido comprobar que tras realizar 20 consultas y calcular el promedio, este converge hacia el número real de alumnos con todas las asignaturas suspendidas (420). En otras palabras, conseguimos anular el efecto protector del ruido introducido por el mecanismo de Laplace, obteniendo la misma información que proporcionaba el método count_all_fail, pero utilizando dp_count_all_fail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "name": "pra1-notebook.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
